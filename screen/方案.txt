特点：

标题栏：双候选（0 / 自动检测值）打分选最优

生命球：中轴竖向扫描 + 水平扫描做“正圆校验”（不圆就降权/剔除）

矩形：统一半开区间（切图、坐标、绘制完全一致）

取整：min 用 floor，max 用 ceil（按你要求偏大，不漏像素）

import cv2
import numpy as np
import math
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any, List


@dataclass(frozen=True)
class Rect:
    # Half-open interval: [x1, x2), [y1, y2)
    x1: int
    y1: int
    x2: int
    y2: int

    def width(self) -> int:
        return max(0, self.x2 - self.x1)

    def height(self) -> int:
        return max(0, self.y2 - self.y1)

    def clamp(self, w: int, h: int) -> "Rect":
        x1 = max(0, min(self.x1, w))
        y1 = max(0, min(self.y1, h))
        x2 = max(0, min(self.x2, w))
        y2 = max(0, min(self.y2, h))
        if x2 < x1:
            x1, x2 = x2, x1
        if y2 < y1:
            y1, y2 = y2, y1
        if x2 == x1:
            x2 = min(w, x1 + 1)
        if y2 == y1:
            y2 = min(h, y1 + 1)
        return Rect(x1, y1, x2, y2)

    def to_cv2_p1p2(self) -> Tuple[Tuple[int, int], Tuple[int, int]]:
        # cv2.rectangle uses inclusive points visually; convert half-open to inclusive end
        p1 = (self.x1, self.y1)
        p2 = (max(self.x1, self.x2 - 1), max(self.y1, self.y2 - 1))
        return p1, p2


class GuildWars2UIDetector:
    # Fitted from your labeled set (8 samples)
    ORB_GAP_A = 0.29
    ORB_GAP_B = 1.0

    CAST_W_RATIO = 3.85
    CAST_TOP_FROM_ORB_BOTTOM_RATIO = 4.40
    CAST_H_RATIO = 0.26

    def __init__(self) -> None:
        pass

    @staticmethod
    def _auto_detect_titlebar(img: np.ndarray) -> int:
        h = img.shape[0]
        if h < 60:
            return 0

        check = img[0:10, :, :]
        if check.size == 0:
            return 0
        gray = cv2.cvtColor(check, cv2.COLOR_BGR2GRAY)
        std = float(np.std(gray))

        # If top is complex, likely no titlebar (fullscreen), but can be false.
        # We still return a candidate (0) and let scoring decide.
        if std > 10.0:
            return 0

        search_h = min(60, h)
        top = img[0:search_h, :, :]
        g = cv2.cvtColor(top, cv2.COLOR_BGR2GRAY).astype(np.float32)

        # Row gradients
        grad = np.mean(np.abs(np.diff(g, axis=0)), axis=1)
        split = int(np.argmax(grad))

        # Reasonable band for Windows titlebar-ish area
        if grad[split] > 15.0 and 15 < split < 55:
            return split + 1
        return 0

    @staticmethod
    def _redness_score_line(bgr: np.ndarray, x: int) -> np.ndarray:
        H, W = bgr.shape[:2]
        xs = [max(0, min(x + dx, W - 1)) for dx in (-1, 0, 1)]
        b = bgr[:, xs, 0].astype(np.int16)
        g = bgr[:, xs, 1].astype(np.int16)
        r = bgr[:, xs, 2].astype(np.int16)
        m = np.maximum(b, g)
        s = np.clip(r - m, 0, 255)
        return s.mean(axis=1).astype(np.float32)

    @staticmethod
    def _redness_score_row(bgr: np.ndarray, y: int) -> np.ndarray:
        H, W = bgr.shape[:2]
        ys = [max(0, min(y + dy, H - 1)) for dy in (-1, 0, 1)]
        b = bgr[ys, :, 0].astype(np.int16)
        g = bgr[ys, :, 1].astype(np.int16)
        r = bgr[ys, :, 2].astype(np.int16)
        m = np.maximum(b, g)
        s = np.clip(r - m, 0, 255)
        return s.mean(axis=0).astype(np.float32)

    @staticmethod
    def _find_best_run_1d(score: np.ndarray, start: int, end: int,
                         min_len: int, max_len: int) -> Optional[Tuple[int, int, float]]:
        win = score[start:end]
        if win.size == 0:
            return None
        p90 = float(np.percentile(win, 90))
        thr = max(20.0, 0.5 * p90)

        mask = (score > thr).astype(np.uint8)
        mask[:start] = 0
        mask[end:] = 0

        best = None
        best_score = None

        i = start
        while i < end:
            if mask[i] == 0:
                i += 1
                continue
            j = i
            while j < end and mask[j] == 1:
                j += 1
            top = i
            bot = j - 1
            length = bot - top + 1
            if length < min_len or length > max_len:
                i = j
                continue

            s = float(score[top:bot + 1].sum())
            if best_score is None or s > best_score:
                best_score = s
                best = (top, bot, s)
            i = j

        return best

    def _detect_orb_client(self, client: np.ndarray) -> Optional[Dict[str, Any]]:
        Hc, W = client.shape[:2]
        cx = W / 2.0
        x = int(round(cx))

        score_v = self._redness_score_line(client, x)
        score_v = np.convolve(score_v, np.array([0.25, 0.5, 0.25], dtype=np.float32), mode="same")

        y_min = int(Hc * 0.45)
        y_max = Hc

        min_len = int(max(6, round(0.05 * Hc)))
        max_len = int(max(min_len + 2, round(0.25 * Hc)))

        run = self._find_best_run_1d(score_v, y_min, y_max, min_len, max_len)
        if run is None:
            return None

        top, bottom, v_sum = run
        Rv_raw = (bottom - top) / 2.0
        cy_raw = (top + bottom) / 2.0

        # Horizontal circle check near cy_raw
        y = int(round(cy_raw))
        score_h = self._redness_score_row(client, y)
        score_h = np.convolve(score_h, np.array([0.25, 0.5, 0.25], dtype=np.float32), mode="same")

        x_min = int(W * 0.20)
        x_max = int(W * 0.80)

        min_len_h = int(max(6, round(0.05 * Hc)))
        max_len_h = int(max(min_len_h + 2, round(0.30 * Hc)))

        run_h = self._find_best_run_1d(score_h, x_min, x_max, min_len_h, max_len_h)
        if run_h is None:
            return None

        left, right, h_sum = run_h
        Rh_raw = (right - left) / 2.0
        cx_h = (left + right) / 2.0

        # Enforce midline axiom: orb center x == W/2, but use Rh as a circle sanity check
        if Rv_raw <= 0.0 or Rh_raw <= 0.0:
            return None

        # Circle tolerance: horizontal/vertical radius should be close
        ratio = Rh_raw / Rv_raw
        if ratio < 0.80 or ratio > 1.25:
            return None

        # Make radius "regular": integer pixels
        R = float(max(1, int(round((Rv_raw + Rh_raw) / 2.0))))

        # Use bottom gap model to stabilize orb bottom
        gap = self.ORB_GAP_A * R + self.ORB_GAP_B
        orb_bottom = Hc - gap
        orb_cy = orb_bottom - R

        return {
            "W": W,
            "H": Hc,
            "cx": W / 2.0,
            "R": R,
            "gap": gap,
            "orb_bottom": orb_bottom,
            "orb_cy": orb_cy,
            "raw": {
                "top": top, "bottom": bottom, "Rv_raw": Rv_raw, "cy_raw": cy_raw, "v_sum": v_sum,
                "left": left, "right": right, "Rh_raw": Rh_raw, "cx_h": cx_h, "h_sum": h_sum,
                "ratio": ratio,
            }
        }

    def _compute_boxes_from_orb(self, orb: Dict[str, Any], yoff: int, img_w: int, img_h: int) -> Tuple[Rect, Rect]:
        cx = float(orb["cx"])
        R = float(orb["R"])
        orb_cy_img = float(orb["orb_cy"]) + float(yoff)
        orb_bottom_client = float(orb["orb_bottom"])

        cast_w = self.CAST_W_RATIO * R
        cast_h = self.CAST_H_RATIO * R
        cast_top_client = orb_bottom_client - self.CAST_TOP_FROM_ORB_BOTTOM_RATIO * R
        cast_top_img = cast_top_client + yoff

        # Half-open: mins floor, maxs ceil
        cast = Rect(
            int(math.floor(cx - cast_w / 2.0)),
            int(math.floor(cast_top_img)),
            int(math.ceil(cx + cast_w / 2.0)),
            int(math.ceil(cast_top_img + cast_h)),
        ).clamp(img_w, img_h)

        orb_box = Rect(
            int(math.floor(cx - R)),
            int(math.floor(orb_cy_img - R)),
            int(math.ceil(cx + R)),
            int(math.ceil(orb_cy_img + R)),
        ).clamp(img_w, img_h)

        return orb_box, cast

    def detect(self, image_path: str, overlay_out: Optional[str] = None,
               crop_orb_out: Optional[str] = None, crop_cast_out: Optional[str] = None) -> Dict[str, Any]:
        img = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if img is None:
            raise RuntimeError("cannot read image: " + str(image_path))

        H, W = img.shape[:2]

        yoff_auto = self._auto_detect_titlebar(img)
        candidates: List[int] = []
        candidates.append(0)
        if yoff_auto not in candidates:
            candidates.append(yoff_auto)

        best = None
        best_score = None

        for yoff in candidates:
            client = img[yoff:, :, :]
            orb = self._detect_orb_client(client)
            if orb is None:
                continue

            # Score: prefer orb close to bottom, and good circle ratio
            gap = float(orb["gap"])
            R = float(orb["R"])
            ratio = float(orb["raw"]["ratio"])
            orb_bottom = float(orb["orb_bottom"])
            Hc = float(orb["H"])

            # orb_bottom should be near Hc (because gap is small)
            bottomness = 1.0 - abs((Hc - orb_bottom) - gap) / max(1.0, Hc)
            circle = 1.0 - abs(1.0 - ratio)
            score = 1000.0 * bottomness + 200.0 * circle + 0.5 * (orb["raw"]["v_sum"] + orb["raw"]["h_sum"])

            if best_score is None or score > best_score:
                best_score = score
                best = (yoff, orb)

        if best is None:
            raise RuntimeError("orb not found under any titlebar hypothesis")

        yoff, orb = best
        orb_box, cast_box = self._compute_boxes_from_orb(orb, yoff, W, H)

        result: Dict[str, Any] = {
            "titlebar_offset": int(yoff),
            "orb_box": (orb_box.x1, orb_box.y1, orb_box.x2, orb_box.y2),
            "cast_box": (cast_box.x1, cast_box.y1, cast_box.x2, cast_box.y2),
            "orb_radius": float(orb["R"]),
            "debug": {
                "yoff_candidates": candidates,
                "chosen_yoff": int(yoff),
                "raw": orb["raw"],
            }
        }

        if overlay_out is not None or crop_orb_out is not None or crop_cast_out is not None:
            vis = img.copy()

            # midline
            cv2.line(vis, (W // 2, 0), (W // 2, H - 1), (255, 255, 0), 1)
            if yoff > 0:
                cv2.line(vis, (0, yoff), (W - 1, yoff), (255, 0, 255), 1)

            p1, p2 = orb_box.to_cv2_p1p2()
            cv2.rectangle(vis, p1, p2, (0, 255, 0), 2)

            p1, p2 = cast_box.to_cv2_p1p2()
            cv2.rectangle(vis, p1, p2, (0, 255, 255), 2)

            if overlay_out is not None:
                cv2.imwrite(overlay_out, vis)

            if crop_orb_out is not None:
                crop = img[orb_box.y1:orb_box.y2, orb_box.x1:orb_box.x2].copy()
                cv2.imwrite(crop_orb_out, crop)

            if crop_cast_out is not None:
                crop = img[cast_box.y1:cast_box.y2, cast_box.x1:cast_box.x2].copy()
                cv2.imwrite(crop_cast_out, crop)

        return result


def main() -> None:
    det = GuildWars2UIDetector()
    image_path = "8.png"

    r = det.detect(
        image_path,
        overlay_out="8_overlay_fused.png",
        crop_orb_out="8_orb_fused.png",
        crop_cast_out="8_cast_fused.png",
    )

    print("titlebar_offset =", r["titlebar_offset"])
    print("orb_box =", r["orb_box"])
    print("cast_box =", r["cast_box"])
    print("orb_radius =", r["orb_radius"])


if __name__ == "__main__":
    main()


ID,分辨率 (W×H),中轴 X,"施法条 (Cast Bar) 校正坐标  [xmin​,ymin​,xmax​,ymax​]","生命球 (Health Orb) 校正坐标  [xmin​,ymin​,xmax​,ymax​]",备注
1,992×661,496,"[418,469,574,478]","[454,565,538,649]",标准
2,622×661,311,"[252,517,370,524]","[280,589,342,651]",已修正X轴偏移
3,1628×661,814,"[736,469,892,478]","[772,565,856,649]",宽屏
4,1628×951,814,"[716,713,912,726]","[763,834,865,936]",高UI缩放
5,2560×1440,1280,"[1183,1203,1377,1216]","[1229,1324,1331,1426]",2K分辨率
6,538×420,269,"[222,302,316,307]","[243,361,295,413]",小窗口
7,538×1002,269,"[218,878,320,883]","[242,940,296,994]",竖屏
8,904×190,452,"[433,142,471,144]","[441,165,463,187]",扁平窗口

1（992×661）y-37标题：施法条：418，469   574，478。红圈：496，566   496，648   454，607  537，607
2（622×661）y-37标题：施法条：252，517   369，524。红圈：331，589   331，651   280，620  341，620
3（1628×661）y-37标题：施法条：735，469   890，478。红圈：814，566   814，648   772，607  854，607
4（1628×951）y-37标题：施法条：717，713   910，726。红圈：814，834   814，935   763，885  864，885
5（2560×1440）：施法条：1184，1203   1379，1216。红圈：1280，1324   1280，1425   1229，1375  1330，1375
6（538×420）y-37标题：施法条：222，302   315，307。红圈：269，361   269，412   243，386  294，386
7（538×1002）y-37标题：施法条：218，878   317，883。红圈：269，940   269，993   242，966  296，966
8（904×190）y-37标题：：施法条：433，142   470，144。红圈：452，166   452，186   441，175  462，175